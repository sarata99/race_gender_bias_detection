{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distilbert_base_uncased_SVM_RF_MLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c37a87e9b0ce4809828460fa375bd8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1b385e2cb09244cc8d4cc76a3c639e55",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_45bee9b894ef4e83975523149aa3b7b2",
              "IPY_MODEL_caba5bd4fd494c2293b4c6e3e3032f71"
            ]
          }
        },
        "1b385e2cb09244cc8d4cc76a3c639e55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45bee9b894ef4e83975523149aa3b7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d0fc95901f604bb087968948018918af",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_032d20708ebe41a5b62c1a92c76e1cd2"
          }
        },
        "caba5bd4fd494c2293b4c6e3e3032f71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_83121fdf3e1b450e865b33b7c389b6bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 735kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fbc8eaf82a2042adb5956eec32c0a700"
          }
        },
        "d0fc95901f604bb087968948018918af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "032d20708ebe41a5b62c1a92c76e1cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "83121fdf3e1b450e865b33b7c389b6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fbc8eaf82a2042adb5956eec32c0a700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "678056d450e54882878f09d355ea87d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3afe22b2fa744680a2c7f835eeef78e8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61dd50f1ea794c09847d5d11611b270d",
              "IPY_MODEL_df4969da3cda4496b20e16b904bb35b8"
            ]
          }
        },
        "3afe22b2fa744680a2c7f835eeef78e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61dd50f1ea794c09847d5d11611b270d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d55298c01ce34f498517d6fed8999831",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5acc16f82047478eafb1adba206c4f08"
          }
        },
        "df4969da3cda4496b20e16b904bb35b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8e7e8ba8e38f415ca7c7773a9566d7db",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 372B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a7511a776e845298cb340caa3651219"
          }
        },
        "d55298c01ce34f498517d6fed8999831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5acc16f82047478eafb1adba206c4f08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8e7e8ba8e38f415ca7c7773a9566d7db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a7511a776e845298cb340caa3651219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b10647abdb7b46669da9994c88570644": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8dc5d2330d7d49de94db8a6d6bae376c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_826e1ce741564b0cbc49f5488d41c371",
              "IPY_MODEL_02f6437572e64da3957a146fc50fadf2"
            ]
          }
        },
        "8dc5d2330d7d49de94db8a6d6bae376c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "826e1ce741564b0cbc49f5488d41c371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_df9ae3c9de854147baaf967bb310feb9",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1f705f241c844d30be745383a1a94ea5"
          }
        },
        "02f6437572e64da3957a146fc50fadf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_038b1de901f64795b316ba87139e1e20",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.88MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f4d816277ef4769a9a41d65d87aa69f"
          }
        },
        "df9ae3c9de854147baaf967bb310feb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1f705f241c844d30be745383a1a94ea5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "038b1de901f64795b316ba87139e1e20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f4d816277ef4769a9a41d65d87aa69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbBwB6nH1MBE",
        "outputId": "779bd528-f0cc-4249-9564-d1b26710a2b2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy\n",
        "import os\n",
        "\n",
        "import nltk\n",
        "\n",
        "import torch\n",
        "!pip install transformers\n",
        "import transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.1MB 17.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 901kB 50.9MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.3MB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFY-NCHu2GNk"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()\n",
        "\n",
        "import torch\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    torch.cuda.empty_cache()\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "BcviZNM22KpO",
        "outputId": "8abe8b23-add5-4501-9d5a-30eea31821fe"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fb3da292-83e3-467e-b12d-5361400d032a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fb3da292-83e3-467e-b12d-5361400d032a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving FA18_messages_with_gender_recipients_hand_lableled.xlsx to FA18_messages_with_gender_recipients_hand_lableled.xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "j9J9tNtl3Cci",
        "outputId": "30a0e047-5bd8-49d6-c755-1cf65d840b88"
      },
      "source": [
        "# Read in excel file with recipient gender hand labeled \n",
        "df_fall_18_messages = pd.read_excel('FA18_messages_with_gender_recipients_hand_lableled.xlsx', index_col=0)\n",
        "print(df_fall_18_messages.shape)\n",
        "df_fall_18_messages.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5039, 5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>User ID</th>\n",
              "      <th>Sender Race</th>\n",
              "      <th>Sender Gender</th>\n",
              "      <th>Recipient Gender</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>42683026</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>Hey @Katie Poteet I know you said we should em...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>25501571</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>@Mary Cassell I would email Dr. K anyway with ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>42683026</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>Ok, thanks a lot. I have the email typed but w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>25501571</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>Upstairs from our lecture hall</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>25501571</td>\n",
              "      <td>WHITE</td>\n",
              "      <td>F</td>\n",
              "      <td>F</td>\n",
              "      <td>Sherman 207!!!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    User ID  ...                                               Text\n",
              "0  42683026  ...  Hey @Katie Poteet I know you said we should em...\n",
              "1  25501571  ...  @Mary Cassell I would email Dr. K anyway with ...\n",
              "2  42683026  ...  Ok, thanks a lot. I have the email typed but w...\n",
              "3  25501571  ...                     Upstairs from our lecture hall\n",
              "4  25501571  ...                                     Sherman 207!!!\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Lsy4PAEc3Gkd",
        "outputId": "7c5622a6-81b5-4bff-9655-9f041217fe31"
      },
      "source": [
        "# Encode recipient gender char as int and create as new column in dataframe\n",
        "# Remove rows where recipient's gender is unknown\n",
        "male_val = 0\n",
        "female_val = 1\n",
        "neutral_val = 2\n",
        "\n",
        "def encode(c):\n",
        "    if (c == 'M'):\n",
        "        return male_val\n",
        "    elif (c == 'F'):\n",
        "        return female_val\n",
        "    elif (c == 'N'):\n",
        "        return neutral_val\n",
        "\n",
        "# Add column in dataframe for encoded gender\n",
        "df_fall_18_messages['Recipient Gender Encoded'] = [encode(x) for x in df_fall_18_messages['Recipient Gender']]\n",
        "# Drop nas (some genders were unknown in the dataset)\n",
        "df_fall_18_messages = df_fall_18_messages[df_fall_18_messages['Recipient Gender Encoded'].notna()]\n",
        "\n",
        "data = [df_fall_18_messages['Text'], df_fall_18_messages['Recipient Gender Encoded']]\n",
        "\n",
        "headers = ['Text', 'Recipient Gender Encoded']\n",
        "\n",
        "df_fall_18_messages = pd.concat(data, axis=1, keys=headers)\n",
        "\n",
        "print(df_fall_18_messages.shape)\n",
        "df_fall_18_messages.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4872, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Recipient Gender Encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hey @Katie Poteet I know you said we should em...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@Mary Cassell I would email Dr. K anyway with ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ok, thanks a lot. I have the email typed but w...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Upstairs from our lecture hall</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sherman 207!!!</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text  Recipient Gender Encoded\n",
              "0  Hey @Katie Poteet I know you said we should em...                       1.0\n",
              "1  @Mary Cassell I would email Dr. K anyway with ...                       1.0\n",
              "2  Ok, thanks a lot. I have the email typed but w...                       1.0\n",
              "3                     Upstairs from our lecture hall                       1.0\n",
              "4                                     Sherman 207!!!                       1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbxv9AgM3I4s",
        "outputId": "be7fa0d4-98ee-4275-f0fc-399a9eb779ba"
      },
      "source": [
        "nltk.download('punkt')\n",
        "df_fall_18_sentences = pd.DataFrame(columns=['Sentence', 'Recipient Gender'])\n",
        "counter = 0\n",
        "for index, row in df_fall_18_messages.iterrows():\n",
        "    for sentence in nltk.tokenize.sent_tokenize(row['Text']):\n",
        "        values_to_add = {'Sentence': sentence, 'Recipient Gender': row['Recipient Gender Encoded']}\n",
        "        row_to_add = pd.Series(values_to_add, name = counter)\n",
        "        df_fall_18_sentences = df_fall_18_sentences.append(row_to_add)\n",
        "        counter += 1"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "iDSpa4AV3KpF",
        "outputId": "ab2bda75-aecb-44a7-a5bf-f56b20bf9a76"
      },
      "source": [
        "print(numpy.argwhere(numpy.isnan(numpy.array(df_fall_18_sentences['Recipient Gender']))))\n",
        "print(df_fall_18_sentences.shape)\n",
        "df_fall_18_sentences.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "(6354, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Recipient Gender</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hey @Katie Poteet I know you said we should em...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Iâ€™m planning to do the Baltimore Community Too...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@Mary Cassell I would email Dr. K anyway with ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>If not, itâ€™s still good for her to know what y...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ok, thanks a lot.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Sentence  Recipient Gender\n",
              "0  Hey @Katie Poteet I know you said we should em...               1.0\n",
              "1  Iâ€™m planning to do the Baltimore Community Too...               1.0\n",
              "2  @Mary Cassell I would email Dr. K anyway with ...               1.0\n",
              "3  If not, itâ€™s still good for her to know what y...               1.0\n",
              "4                                  Ok, thanks a lot.               1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1wxsvhju3Md3",
        "outputId": "bcb32897-7547-4a34-cd6e-1ba2d72bdb59"
      },
      "source": [
        "print(df_fall_18_sentences['Recipient Gender'].value_counts())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0    2918\n",
            "1.0    1794\n",
            "0.0    1642\n",
            "Name: Recipient Gender, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmSBLmAX3UQI"
      },
      "source": [
        "# Get the lists of sentences and their labels.\n",
        "sentences = df_fall_18_sentences['Sentence'].values\n",
        "labels = df_fall_18_sentences['Recipient Gender'].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY9-iiOp3ayy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "c37a87e9b0ce4809828460fa375bd8fc",
            "1b385e2cb09244cc8d4cc76a3c639e55",
            "45bee9b894ef4e83975523149aa3b7b2",
            "caba5bd4fd494c2293b4c6e3e3032f71",
            "d0fc95901f604bb087968948018918af",
            "032d20708ebe41a5b62c1a92c76e1cd2",
            "83121fdf3e1b450e865b33b7c389b6bb",
            "fbc8eaf82a2042adb5956eec32c0a700",
            "678056d450e54882878f09d355ea87d3",
            "3afe22b2fa744680a2c7f835eeef78e8",
            "61dd50f1ea794c09847d5d11611b270d",
            "df4969da3cda4496b20e16b904bb35b8",
            "d55298c01ce34f498517d6fed8999831",
            "5acc16f82047478eafb1adba206c4f08",
            "8e7e8ba8e38f415ca7c7773a9566d7db",
            "0a7511a776e845298cb340caa3651219",
            "b10647abdb7b46669da9994c88570644",
            "8dc5d2330d7d49de94db8a6d6bae376c",
            "826e1ce741564b0cbc49f5488d41c371",
            "02f6437572e64da3957a146fc50fadf2",
            "df9ae3c9de854147baaf967bb310feb9",
            "1f705f241c844d30be745383a1a94ea5",
            "038b1de901f64795b316ba87139e1e20",
            "2f4d816277ef4769a9a41d65d87aa69f"
          ]
        },
        "outputId": "fd9eaeca-2d7b-498c-e199-256e6c2a8818"
      },
      "source": [
        "# Initialize the tokenizer with a pretrained model\n",
        "tokenizer = transformers.BertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c37a87e9b0ce4809828460fa375bd8fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "678056d450e54882878f09d355ea87d3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_wâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b10647abdb7b46669da9994c88570644",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oI9qg1bc4RvP"
      },
      "source": [
        "# Convert the string \"granola bars\" to tokenized vocabulary IDs\n",
        "sentence_ids = df_fall_18_sentences['Sentence'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJlygKKM44Qh",
        "outputId": "7dda0375-be0a-422a-c55e-f4caaf7bf503"
      },
      "source": [
        "max_len = 0\n",
        "for id_vector in sentence_ids.values:\n",
        "    if len(id_vector) > max_len:\n",
        "        max_len = len(id_vector)\n",
        "\n",
        "padded_ids = numpy.array([i + [0]*(max_len-len(i)) for i in sentence_ids.values])\n",
        "print(\"max id array length: \", max_len)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max id array length:  105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuwgM-mv5Lx9",
        "outputId": "bef9345e-d1d3-4edc-cc3d-6f3e8808e54d"
      },
      "source": [
        "attention_mask = numpy.where(padded_ids != 0, 1, 0)\n",
        "print(attention_mask.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6354, 105)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyDKAqeC5epO"
      },
      "source": [
        "# Convert lists to tensors\n",
        "ids_tensor = torch.LongTensor(padded_ids)\n",
        "attention_masks_tensor = torch.tensor(attention_mask)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWnTuD4x9cQV"
      },
      "source": [
        "ids_batches = torch.tensor_split(ids_tensor, 10)\n",
        "attention_masks_batches = torch.tensor_split(attention_masks_tensor, 10)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnJKnpgt5uP3",
        "outputId": "b05f3570-af66-490a-876d-ef08b90823a2"
      },
      "source": [
        "model = transformers.BertModel.from_pretrained('distilbert-base-uncased', output_hidden_states=True)\n",
        "# Set the device to GPU (cuda) if available, otherwise stick with CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = model.to(device)\n",
        "model.eval()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using a model of type distilbert to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing BertModel: ['distilbert.embeddings.word_embeddings.weight', 'distilbert.embeddings.position_embeddings.weight', 'distilbert.embeddings.LayerNorm.weight', 'distilbert.embeddings.LayerNorm.bias', 'distilbert.transformer.layer.0.attention.q_lin.weight', 'distilbert.transformer.layer.0.attention.q_lin.bias', 'distilbert.transformer.layer.0.attention.k_lin.weight', 'distilbert.transformer.layer.0.attention.k_lin.bias', 'distilbert.transformer.layer.0.attention.v_lin.weight', 'distilbert.transformer.layer.0.attention.v_lin.bias', 'distilbert.transformer.layer.0.attention.out_lin.weight', 'distilbert.transformer.layer.0.attention.out_lin.bias', 'distilbert.transformer.layer.0.sa_layer_norm.weight', 'distilbert.transformer.layer.0.sa_layer_norm.bias', 'distilbert.transformer.layer.0.ffn.lin1.weight', 'distilbert.transformer.layer.0.ffn.lin1.bias', 'distilbert.transformer.layer.0.ffn.lin2.weight', 'distilbert.transformer.layer.0.ffn.lin2.bias', 'distilbert.transformer.layer.0.output_layer_norm.weight', 'distilbert.transformer.layer.0.output_layer_norm.bias', 'distilbert.transformer.layer.1.attention.q_lin.weight', 'distilbert.transformer.layer.1.attention.q_lin.bias', 'distilbert.transformer.layer.1.attention.k_lin.weight', 'distilbert.transformer.layer.1.attention.k_lin.bias', 'distilbert.transformer.layer.1.attention.v_lin.weight', 'distilbert.transformer.layer.1.attention.v_lin.bias', 'distilbert.transformer.layer.1.attention.out_lin.weight', 'distilbert.transformer.layer.1.attention.out_lin.bias', 'distilbert.transformer.layer.1.sa_layer_norm.weight', 'distilbert.transformer.layer.1.sa_layer_norm.bias', 'distilbert.transformer.layer.1.ffn.lin1.weight', 'distilbert.transformer.layer.1.ffn.lin1.bias', 'distilbert.transformer.layer.1.ffn.lin2.weight', 'distilbert.transformer.layer.1.ffn.lin2.bias', 'distilbert.transformer.layer.1.output_layer_norm.weight', 'distilbert.transformer.layer.1.output_layer_norm.bias', 'distilbert.transformer.layer.2.attention.q_lin.weight', 'distilbert.transformer.layer.2.attention.q_lin.bias', 'distilbert.transformer.layer.2.attention.k_lin.weight', 'distilbert.transformer.layer.2.attention.k_lin.bias', 'distilbert.transformer.layer.2.attention.v_lin.weight', 'distilbert.transformer.layer.2.attention.v_lin.bias', 'distilbert.transformer.layer.2.attention.out_lin.weight', 'distilbert.transformer.layer.2.attention.out_lin.bias', 'distilbert.transformer.layer.2.sa_layer_norm.weight', 'distilbert.transformer.layer.2.sa_layer_norm.bias', 'distilbert.transformer.layer.2.ffn.lin1.weight', 'distilbert.transformer.layer.2.ffn.lin1.bias', 'distilbert.transformer.layer.2.ffn.lin2.weight', 'distilbert.transformer.layer.2.ffn.lin2.bias', 'distilbert.transformer.layer.2.output_layer_norm.weight', 'distilbert.transformer.layer.2.output_layer_norm.bias', 'distilbert.transformer.layer.3.attention.q_lin.weight', 'distilbert.transformer.layer.3.attention.q_lin.bias', 'distilbert.transformer.layer.3.attention.k_lin.weight', 'distilbert.transformer.layer.3.attention.k_lin.bias', 'distilbert.transformer.layer.3.attention.v_lin.weight', 'distilbert.transformer.layer.3.attention.v_lin.bias', 'distilbert.transformer.layer.3.attention.out_lin.weight', 'distilbert.transformer.layer.3.attention.out_lin.bias', 'distilbert.transformer.layer.3.sa_layer_norm.weight', 'distilbert.transformer.layer.3.sa_layer_norm.bias', 'distilbert.transformer.layer.3.ffn.lin1.weight', 'distilbert.transformer.layer.3.ffn.lin1.bias', 'distilbert.transformer.layer.3.ffn.lin2.weight', 'distilbert.transformer.layer.3.ffn.lin2.bias', 'distilbert.transformer.layer.3.output_layer_norm.weight', 'distilbert.transformer.layer.3.output_layer_norm.bias', 'distilbert.transformer.layer.4.attention.q_lin.weight', 'distilbert.transformer.layer.4.attention.q_lin.bias', 'distilbert.transformer.layer.4.attention.k_lin.weight', 'distilbert.transformer.layer.4.attention.k_lin.bias', 'distilbert.transformer.layer.4.attention.v_lin.weight', 'distilbert.transformer.layer.4.attention.v_lin.bias', 'distilbert.transformer.layer.4.attention.out_lin.weight', 'distilbert.transformer.layer.4.attention.out_lin.bias', 'distilbert.transformer.layer.4.sa_layer_norm.weight', 'distilbert.transformer.layer.4.sa_layer_norm.bias', 'distilbert.transformer.layer.4.ffn.lin1.weight', 'distilbert.transformer.layer.4.ffn.lin1.bias', 'distilbert.transformer.layer.4.ffn.lin2.weight', 'distilbert.transformer.layer.4.ffn.lin2.bias', 'distilbert.transformer.layer.4.output_layer_norm.weight', 'distilbert.transformer.layer.4.output_layer_norm.bias', 'distilbert.transformer.layer.5.attention.q_lin.weight', 'distilbert.transformer.layer.5.attention.q_lin.bias', 'distilbert.transformer.layer.5.attention.k_lin.weight', 'distilbert.transformer.layer.5.attention.k_lin.bias', 'distilbert.transformer.layer.5.attention.v_lin.weight', 'distilbert.transformer.layer.5.attention.v_lin.bias', 'distilbert.transformer.layer.5.attention.out_lin.weight', 'distilbert.transformer.layer.5.attention.out_lin.bias', 'distilbert.transformer.layer.5.sa_layer_norm.weight', 'distilbert.transformer.layer.5.sa_layer_norm.bias', 'distilbert.transformer.layer.5.ffn.lin1.weight', 'distilbert.transformer.layer.5.ffn.lin1.bias', 'distilbert.transformer.layer.5.ffn.lin2.weight', 'distilbert.transformer.layer.5.ffn.lin2.bias', 'distilbert.transformer.layer.5.output_layer_norm.weight', 'distilbert.transformer.layer.5.output_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['embeddings.word_embeddings.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.LayerNorm.bias', 'pooler.dense.weight', 'pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lQwhuA86lz4"
      },
      "source": [
        "hidden_states = []\n",
        "for i in range(0,len(ids_batches)):\n",
        "  with torch.no_grad():\n",
        "    ids_batch = ids_batches[i].to(device)\n",
        "    attention_masks_batch = attention_masks_batches[i].to(device)\n",
        "    hidden_state = model(ids_batch, attention_mask=attention_masks_batch)\n",
        "    states = torch.mean(hidden_state[2][-2], dim=1).squeeze().cpu()\n",
        "    for sentence in states: \n",
        "      hidden_states.append(sentence)\n",
        "    ids_batch.cpu()\n",
        "    attention_masks_batch.cpu()\n",
        "    del hidden_state, ids_batch, attention_masks_batch\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx-7Y8WfOXKs",
        "outputId": "184a6b7b-355d-4b3b-91f1-32e683b937ca"
      },
      "source": [
        "print(\"len(hidden_states): \",len(hidden_states))\n",
        "print(\"hidden_states[0].shape: \",hidden_states[0].shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len(hidden_states):  6354\n",
            "hidden_states[0].shape:  torch.Size([768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFPqhRP-6Aqk"
      },
      "source": [
        "numpy_array = []\n",
        "for tensor in hidden_states:\n",
        "  numpy_array.append(tensor.numpy())\n",
        "\n",
        "X = numpy.array(numpy_array)\n",
        "y = df_fall_18_sentences[\"Recipient Gender\"]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "2x5HLsbOVfvk",
        "outputId": "9a794bbb-f0a9-473c-b81c-45628b0ab65a"
      },
      "source": [
        "df_features = pd.DataFrame(X)\n",
        "df_features.sample(10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>728</th>\n",
              "      <th>729</th>\n",
              "      <th>730</th>\n",
              "      <th>731</th>\n",
              "      <th>732</th>\n",
              "      <th>733</th>\n",
              "      <th>734</th>\n",
              "      <th>735</th>\n",
              "      <th>736</th>\n",
              "      <th>737</th>\n",
              "      <th>738</th>\n",
              "      <th>739</th>\n",
              "      <th>740</th>\n",
              "      <th>741</th>\n",
              "      <th>742</th>\n",
              "      <th>743</th>\n",
              "      <th>744</th>\n",
              "      <th>745</th>\n",
              "      <th>746</th>\n",
              "      <th>747</th>\n",
              "      <th>748</th>\n",
              "      <th>749</th>\n",
              "      <th>750</th>\n",
              "      <th>751</th>\n",
              "      <th>752</th>\n",
              "      <th>753</th>\n",
              "      <th>754</th>\n",
              "      <th>755</th>\n",
              "      <th>756</th>\n",
              "      <th>757</th>\n",
              "      <th>758</th>\n",
              "      <th>759</th>\n",
              "      <th>760</th>\n",
              "      <th>761</th>\n",
              "      <th>762</th>\n",
              "      <th>763</th>\n",
              "      <th>764</th>\n",
              "      <th>765</th>\n",
              "      <th>766</th>\n",
              "      <th>767</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5729</th>\n",
              "      <td>-0.134583</td>\n",
              "      <td>0.062177</td>\n",
              "      <td>1.458376</td>\n",
              "      <td>0.750637</td>\n",
              "      <td>0.079481</td>\n",
              "      <td>0.083587</td>\n",
              "      <td>-0.131703</td>\n",
              "      <td>-0.062617</td>\n",
              "      <td>-0.675590</td>\n",
              "      <td>-0.700285</td>\n",
              "      <td>0.759642</td>\n",
              "      <td>0.077144</td>\n",
              "      <td>0.429482</td>\n",
              "      <td>-1.202718</td>\n",
              "      <td>-0.415402</td>\n",
              "      <td>-0.788152</td>\n",
              "      <td>-0.066272</td>\n",
              "      <td>-0.248782</td>\n",
              "      <td>-1.319824</td>\n",
              "      <td>0.534457</td>\n",
              "      <td>-0.675336</td>\n",
              "      <td>0.128751</td>\n",
              "      <td>0.187158</td>\n",
              "      <td>0.720863</td>\n",
              "      <td>-0.048104</td>\n",
              "      <td>0.047838</td>\n",
              "      <td>-1.272750</td>\n",
              "      <td>-0.804106</td>\n",
              "      <td>-0.172438</td>\n",
              "      <td>1.444689</td>\n",
              "      <td>1.127269</td>\n",
              "      <td>-0.708241</td>\n",
              "      <td>0.347100</td>\n",
              "      <td>-1.396768</td>\n",
              "      <td>0.820770</td>\n",
              "      <td>-0.588736</td>\n",
              "      <td>-0.159436</td>\n",
              "      <td>-0.898084</td>\n",
              "      <td>-1.128461</td>\n",
              "      <td>-0.560359</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.056887</td>\n",
              "      <td>0.731983</td>\n",
              "      <td>0.308551</td>\n",
              "      <td>0.250022</td>\n",
              "      <td>1.920964</td>\n",
              "      <td>1.514480</td>\n",
              "      <td>-2.400119</td>\n",
              "      <td>0.935686</td>\n",
              "      <td>1.378945</td>\n",
              "      <td>-0.489329</td>\n",
              "      <td>-0.781684</td>\n",
              "      <td>-1.538385</td>\n",
              "      <td>-1.553320</td>\n",
              "      <td>0.179927</td>\n",
              "      <td>-1.385678</td>\n",
              "      <td>0.772697</td>\n",
              "      <td>-0.032749</td>\n",
              "      <td>-1.281745</td>\n",
              "      <td>0.304477</td>\n",
              "      <td>1.194919</td>\n",
              "      <td>-0.517236</td>\n",
              "      <td>0.206366</td>\n",
              "      <td>0.988831</td>\n",
              "      <td>1.265005</td>\n",
              "      <td>0.825333</td>\n",
              "      <td>-0.064232</td>\n",
              "      <td>0.630105</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>-0.679610</td>\n",
              "      <td>-0.032482</td>\n",
              "      <td>1.047647</td>\n",
              "      <td>-1.224808</td>\n",
              "      <td>0.944177</td>\n",
              "      <td>0.093853</td>\n",
              "      <td>-0.303051</td>\n",
              "      <td>-1.014945</td>\n",
              "      <td>-1.267905</td>\n",
              "      <td>1.415123</td>\n",
              "      <td>1.648605</td>\n",
              "      <td>1.899328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3847</th>\n",
              "      <td>-0.185526</td>\n",
              "      <td>0.409991</td>\n",
              "      <td>1.526158</td>\n",
              "      <td>0.657484</td>\n",
              "      <td>-0.031235</td>\n",
              "      <td>-0.029933</td>\n",
              "      <td>-0.057835</td>\n",
              "      <td>0.012412</td>\n",
              "      <td>-0.599176</td>\n",
              "      <td>-0.639283</td>\n",
              "      <td>0.493148</td>\n",
              "      <td>0.315974</td>\n",
              "      <td>0.341944</td>\n",
              "      <td>-0.921033</td>\n",
              "      <td>-0.364396</td>\n",
              "      <td>-0.993129</td>\n",
              "      <td>-0.104834</td>\n",
              "      <td>-0.051794</td>\n",
              "      <td>-1.069836</td>\n",
              "      <td>0.454011</td>\n",
              "      <td>-0.814265</td>\n",
              "      <td>0.120317</td>\n",
              "      <td>0.151213</td>\n",
              "      <td>0.755257</td>\n",
              "      <td>0.185715</td>\n",
              "      <td>0.145819</td>\n",
              "      <td>-1.200614</td>\n",
              "      <td>-0.788486</td>\n",
              "      <td>-0.168714</td>\n",
              "      <td>1.544699</td>\n",
              "      <td>1.134223</td>\n",
              "      <td>-0.529618</td>\n",
              "      <td>0.313488</td>\n",
              "      <td>-1.504750</td>\n",
              "      <td>0.771340</td>\n",
              "      <td>-0.593427</td>\n",
              "      <td>0.015597</td>\n",
              "      <td>-0.837215</td>\n",
              "      <td>-1.374135</td>\n",
              "      <td>-0.865145</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.876905</td>\n",
              "      <td>0.829332</td>\n",
              "      <td>0.475114</td>\n",
              "      <td>0.164766</td>\n",
              "      <td>1.664827</td>\n",
              "      <td>1.374231</td>\n",
              "      <td>-2.297637</td>\n",
              "      <td>0.906154</td>\n",
              "      <td>1.395484</td>\n",
              "      <td>-0.829772</td>\n",
              "      <td>-0.653427</td>\n",
              "      <td>-1.075279</td>\n",
              "      <td>-1.576261</td>\n",
              "      <td>0.260424</td>\n",
              "      <td>-1.148408</td>\n",
              "      <td>1.252943</td>\n",
              "      <td>-0.094948</td>\n",
              "      <td>-1.281621</td>\n",
              "      <td>0.526156</td>\n",
              "      <td>1.015856</td>\n",
              "      <td>-0.297670</td>\n",
              "      <td>0.502216</td>\n",
              "      <td>1.072469</td>\n",
              "      <td>1.306626</td>\n",
              "      <td>0.703565</td>\n",
              "      <td>-0.384895</td>\n",
              "      <td>1.110503</td>\n",
              "      <td>-0.047168</td>\n",
              "      <td>-0.673106</td>\n",
              "      <td>-0.209510</td>\n",
              "      <td>0.868151</td>\n",
              "      <td>-1.303756</td>\n",
              "      <td>0.665489</td>\n",
              "      <td>-0.056077</td>\n",
              "      <td>-0.290068</td>\n",
              "      <td>-0.940124</td>\n",
              "      <td>-1.095336</td>\n",
              "      <td>1.282915</td>\n",
              "      <td>1.504017</td>\n",
              "      <td>1.951632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>-0.220425</td>\n",
              "      <td>0.316685</td>\n",
              "      <td>1.346640</td>\n",
              "      <td>0.408896</td>\n",
              "      <td>0.265319</td>\n",
              "      <td>-0.301244</td>\n",
              "      <td>-0.095979</td>\n",
              "      <td>-0.108933</td>\n",
              "      <td>-0.409497</td>\n",
              "      <td>-1.021305</td>\n",
              "      <td>0.759734</td>\n",
              "      <td>0.479804</td>\n",
              "      <td>0.258653</td>\n",
              "      <td>-1.027137</td>\n",
              "      <td>-0.261022</td>\n",
              "      <td>-0.782398</td>\n",
              "      <td>-0.312557</td>\n",
              "      <td>-0.159328</td>\n",
              "      <td>-1.335720</td>\n",
              "      <td>0.467916</td>\n",
              "      <td>-0.374495</td>\n",
              "      <td>-0.201495</td>\n",
              "      <td>0.112832</td>\n",
              "      <td>0.434643</td>\n",
              "      <td>0.488832</td>\n",
              "      <td>0.069889</td>\n",
              "      <td>-1.395032</td>\n",
              "      <td>-0.870054</td>\n",
              "      <td>-0.429886</td>\n",
              "      <td>1.477581</td>\n",
              "      <td>1.002971</td>\n",
              "      <td>-0.693079</td>\n",
              "      <td>0.170930</td>\n",
              "      <td>-1.572942</td>\n",
              "      <td>0.685763</td>\n",
              "      <td>-0.521990</td>\n",
              "      <td>0.024729</td>\n",
              "      <td>-0.628344</td>\n",
              "      <td>-1.095357</td>\n",
              "      <td>-0.464086</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.035529</td>\n",
              "      <td>0.854832</td>\n",
              "      <td>0.199487</td>\n",
              "      <td>-0.008185</td>\n",
              "      <td>1.670516</td>\n",
              "      <td>1.536147</td>\n",
              "      <td>-2.623657</td>\n",
              "      <td>1.068798</td>\n",
              "      <td>1.348374</td>\n",
              "      <td>-0.368591</td>\n",
              "      <td>-0.885712</td>\n",
              "      <td>-1.176792</td>\n",
              "      <td>-1.711401</td>\n",
              "      <td>0.179866</td>\n",
              "      <td>-1.000879</td>\n",
              "      <td>0.733562</td>\n",
              "      <td>-0.121252</td>\n",
              "      <td>-1.493153</td>\n",
              "      <td>0.472086</td>\n",
              "      <td>1.028403</td>\n",
              "      <td>-0.453023</td>\n",
              "      <td>0.477407</td>\n",
              "      <td>1.427713</td>\n",
              "      <td>1.480014</td>\n",
              "      <td>0.759630</td>\n",
              "      <td>-0.019112</td>\n",
              "      <td>1.037655</td>\n",
              "      <td>-0.331805</td>\n",
              "      <td>-0.627794</td>\n",
              "      <td>-0.034036</td>\n",
              "      <td>0.815242</td>\n",
              "      <td>-1.308906</td>\n",
              "      <td>0.838484</td>\n",
              "      <td>0.200985</td>\n",
              "      <td>-0.345366</td>\n",
              "      <td>-1.160704</td>\n",
              "      <td>-1.030709</td>\n",
              "      <td>1.195942</td>\n",
              "      <td>1.423452</td>\n",
              "      <td>2.081895</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5367</th>\n",
              "      <td>-0.124028</td>\n",
              "      <td>0.129488</td>\n",
              "      <td>1.454345</td>\n",
              "      <td>0.379940</td>\n",
              "      <td>0.332330</td>\n",
              "      <td>-0.193410</td>\n",
              "      <td>-0.267970</td>\n",
              "      <td>-0.193186</td>\n",
              "      <td>-0.494114</td>\n",
              "      <td>-0.786532</td>\n",
              "      <td>0.667535</td>\n",
              "      <td>0.084042</td>\n",
              "      <td>0.240157</td>\n",
              "      <td>-1.158189</td>\n",
              "      <td>-0.201820</td>\n",
              "      <td>-0.775880</td>\n",
              "      <td>-0.307374</td>\n",
              "      <td>-0.147605</td>\n",
              "      <td>-1.390272</td>\n",
              "      <td>0.169467</td>\n",
              "      <td>-0.518350</td>\n",
              "      <td>-0.370808</td>\n",
              "      <td>0.225395</td>\n",
              "      <td>0.482324</td>\n",
              "      <td>0.400948</td>\n",
              "      <td>0.023803</td>\n",
              "      <td>-1.318316</td>\n",
              "      <td>-0.974547</td>\n",
              "      <td>-0.187339</td>\n",
              "      <td>1.425212</td>\n",
              "      <td>1.093519</td>\n",
              "      <td>-0.964225</td>\n",
              "      <td>-0.033654</td>\n",
              "      <td>-1.495819</td>\n",
              "      <td>0.641473</td>\n",
              "      <td>-0.694131</td>\n",
              "      <td>0.039091</td>\n",
              "      <td>-0.566424</td>\n",
              "      <td>-1.229164</td>\n",
              "      <td>-0.600123</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.947034</td>\n",
              "      <td>1.003549</td>\n",
              "      <td>0.402193</td>\n",
              "      <td>0.292573</td>\n",
              "      <td>1.810402</td>\n",
              "      <td>1.566386</td>\n",
              "      <td>-2.625088</td>\n",
              "      <td>0.967181</td>\n",
              "      <td>1.264968</td>\n",
              "      <td>-0.547728</td>\n",
              "      <td>-0.957919</td>\n",
              "      <td>-1.375693</td>\n",
              "      <td>-1.844334</td>\n",
              "      <td>0.282453</td>\n",
              "      <td>-1.300300</td>\n",
              "      <td>0.875868</td>\n",
              "      <td>-0.220421</td>\n",
              "      <td>-1.418681</td>\n",
              "      <td>0.411005</td>\n",
              "      <td>1.048532</td>\n",
              "      <td>-0.703991</td>\n",
              "      <td>0.405942</td>\n",
              "      <td>1.203575</td>\n",
              "      <td>1.497059</td>\n",
              "      <td>0.836653</td>\n",
              "      <td>-0.043074</td>\n",
              "      <td>1.040142</td>\n",
              "      <td>-0.354560</td>\n",
              "      <td>-0.681937</td>\n",
              "      <td>-0.144960</td>\n",
              "      <td>0.934124</td>\n",
              "      <td>-1.392545</td>\n",
              "      <td>0.843012</td>\n",
              "      <td>0.083515</td>\n",
              "      <td>-0.354068</td>\n",
              "      <td>-1.015030</td>\n",
              "      <td>-1.121114</td>\n",
              "      <td>1.232159</td>\n",
              "      <td>1.433496</td>\n",
              "      <td>1.921171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>-0.113379</td>\n",
              "      <td>0.173708</td>\n",
              "      <td>1.133063</td>\n",
              "      <td>0.566693</td>\n",
              "      <td>-0.082398</td>\n",
              "      <td>0.027685</td>\n",
              "      <td>0.150972</td>\n",
              "      <td>-0.195874</td>\n",
              "      <td>-0.244477</td>\n",
              "      <td>-1.161581</td>\n",
              "      <td>0.863341</td>\n",
              "      <td>-0.197657</td>\n",
              "      <td>-0.048181</td>\n",
              "      <td>-1.009798</td>\n",
              "      <td>-0.049703</td>\n",
              "      <td>-0.792460</td>\n",
              "      <td>-0.577737</td>\n",
              "      <td>-0.334254</td>\n",
              "      <td>-1.461624</td>\n",
              "      <td>0.131055</td>\n",
              "      <td>-0.807124</td>\n",
              "      <td>0.189774</td>\n",
              "      <td>-0.062996</td>\n",
              "      <td>0.583691</td>\n",
              "      <td>0.187884</td>\n",
              "      <td>0.083347</td>\n",
              "      <td>-1.292990</td>\n",
              "      <td>-0.528285</td>\n",
              "      <td>-0.222694</td>\n",
              "      <td>1.110368</td>\n",
              "      <td>1.063012</td>\n",
              "      <td>-0.614170</td>\n",
              "      <td>0.242130</td>\n",
              "      <td>-1.468193</td>\n",
              "      <td>0.819366</td>\n",
              "      <td>-0.801823</td>\n",
              "      <td>0.077152</td>\n",
              "      <td>-0.857737</td>\n",
              "      <td>-1.428674</td>\n",
              "      <td>-0.637871</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.123008</td>\n",
              "      <td>0.884975</td>\n",
              "      <td>0.382991</td>\n",
              "      <td>-0.243389</td>\n",
              "      <td>1.529260</td>\n",
              "      <td>1.787150</td>\n",
              "      <td>-2.524254</td>\n",
              "      <td>0.845424</td>\n",
              "      <td>1.191188</td>\n",
              "      <td>-0.642582</td>\n",
              "      <td>-1.084860</td>\n",
              "      <td>-1.401992</td>\n",
              "      <td>-1.389976</td>\n",
              "      <td>0.277962</td>\n",
              "      <td>-0.900079</td>\n",
              "      <td>0.829125</td>\n",
              "      <td>-0.562615</td>\n",
              "      <td>-1.411440</td>\n",
              "      <td>0.259220</td>\n",
              "      <td>0.832753</td>\n",
              "      <td>-0.535202</td>\n",
              "      <td>0.467271</td>\n",
              "      <td>0.831708</td>\n",
              "      <td>1.321634</td>\n",
              "      <td>0.448466</td>\n",
              "      <td>-0.058406</td>\n",
              "      <td>1.154334</td>\n",
              "      <td>-0.374504</td>\n",
              "      <td>-0.365788</td>\n",
              "      <td>0.154516</td>\n",
              "      <td>0.954019</td>\n",
              "      <td>-1.409655</td>\n",
              "      <td>0.826149</td>\n",
              "      <td>-0.143839</td>\n",
              "      <td>-0.152122</td>\n",
              "      <td>-1.012895</td>\n",
              "      <td>-1.289962</td>\n",
              "      <td>1.292799</td>\n",
              "      <td>1.295327</td>\n",
              "      <td>2.049123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1566</th>\n",
              "      <td>0.160529</td>\n",
              "      <td>0.144989</td>\n",
              "      <td>1.300389</td>\n",
              "      <td>0.164895</td>\n",
              "      <td>0.394955</td>\n",
              "      <td>-0.072627</td>\n",
              "      <td>0.171109</td>\n",
              "      <td>-0.057952</td>\n",
              "      <td>-0.618398</td>\n",
              "      <td>-0.856623</td>\n",
              "      <td>0.901649</td>\n",
              "      <td>-0.170595</td>\n",
              "      <td>0.065792</td>\n",
              "      <td>-0.763784</td>\n",
              "      <td>-0.231976</td>\n",
              "      <td>-0.582896</td>\n",
              "      <td>-0.193488</td>\n",
              "      <td>-0.299528</td>\n",
              "      <td>-1.765639</td>\n",
              "      <td>-0.275709</td>\n",
              "      <td>-0.667386</td>\n",
              "      <td>-0.009289</td>\n",
              "      <td>0.487068</td>\n",
              "      <td>0.608294</td>\n",
              "      <td>0.095087</td>\n",
              "      <td>0.056703</td>\n",
              "      <td>-1.319514</td>\n",
              "      <td>-0.944724</td>\n",
              "      <td>-0.273152</td>\n",
              "      <td>1.348161</td>\n",
              "      <td>1.145643</td>\n",
              "      <td>-0.905552</td>\n",
              "      <td>-0.154575</td>\n",
              "      <td>-1.360475</td>\n",
              "      <td>0.873818</td>\n",
              "      <td>-0.584717</td>\n",
              "      <td>0.018007</td>\n",
              "      <td>-0.360954</td>\n",
              "      <td>-0.914089</td>\n",
              "      <td>-0.418089</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.688591</td>\n",
              "      <td>0.741193</td>\n",
              "      <td>0.383827</td>\n",
              "      <td>0.080326</td>\n",
              "      <td>1.729090</td>\n",
              "      <td>2.000614</td>\n",
              "      <td>-2.193569</td>\n",
              "      <td>1.127354</td>\n",
              "      <td>0.986540</td>\n",
              "      <td>-0.639167</td>\n",
              "      <td>-0.940502</td>\n",
              "      <td>-1.350174</td>\n",
              "      <td>-1.547626</td>\n",
              "      <td>0.307324</td>\n",
              "      <td>-1.139888</td>\n",
              "      <td>0.619039</td>\n",
              "      <td>0.122729</td>\n",
              "      <td>-1.258752</td>\n",
              "      <td>0.364659</td>\n",
              "      <td>0.931033</td>\n",
              "      <td>-0.458498</td>\n",
              "      <td>0.315898</td>\n",
              "      <td>1.187587</td>\n",
              "      <td>1.198358</td>\n",
              "      <td>0.529045</td>\n",
              "      <td>-0.102946</td>\n",
              "      <td>0.744541</td>\n",
              "      <td>-0.061399</td>\n",
              "      <td>-0.462937</td>\n",
              "      <td>0.115972</td>\n",
              "      <td>0.641836</td>\n",
              "      <td>-1.556872</td>\n",
              "      <td>0.972776</td>\n",
              "      <td>0.005869</td>\n",
              "      <td>-0.292834</td>\n",
              "      <td>-0.825967</td>\n",
              "      <td>-1.034227</td>\n",
              "      <td>1.400331</td>\n",
              "      <td>1.764525</td>\n",
              "      <td>2.005513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2588</th>\n",
              "      <td>-0.141780</td>\n",
              "      <td>0.120551</td>\n",
              "      <td>1.292551</td>\n",
              "      <td>0.523338</td>\n",
              "      <td>0.257252</td>\n",
              "      <td>-0.175934</td>\n",
              "      <td>-0.075576</td>\n",
              "      <td>-0.284766</td>\n",
              "      <td>-0.436444</td>\n",
              "      <td>-1.278380</td>\n",
              "      <td>0.666539</td>\n",
              "      <td>0.012608</td>\n",
              "      <td>0.120770</td>\n",
              "      <td>-0.964636</td>\n",
              "      <td>-0.318880</td>\n",
              "      <td>-0.811816</td>\n",
              "      <td>-0.123898</td>\n",
              "      <td>-0.000065</td>\n",
              "      <td>-1.208981</td>\n",
              "      <td>0.627754</td>\n",
              "      <td>-0.428433</td>\n",
              "      <td>0.230658</td>\n",
              "      <td>0.324187</td>\n",
              "      <td>0.528341</td>\n",
              "      <td>0.085378</td>\n",
              "      <td>-0.074432</td>\n",
              "      <td>-1.350084</td>\n",
              "      <td>-1.169135</td>\n",
              "      <td>-0.431947</td>\n",
              "      <td>1.555434</td>\n",
              "      <td>1.150166</td>\n",
              "      <td>-0.641253</td>\n",
              "      <td>0.101302</td>\n",
              "      <td>-1.286083</td>\n",
              "      <td>0.836248</td>\n",
              "      <td>-0.607508</td>\n",
              "      <td>-0.049046</td>\n",
              "      <td>-0.884392</td>\n",
              "      <td>-1.272928</td>\n",
              "      <td>-0.460276</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.869371</td>\n",
              "      <td>0.965805</td>\n",
              "      <td>0.245301</td>\n",
              "      <td>0.328517</td>\n",
              "      <td>1.812468</td>\n",
              "      <td>1.535384</td>\n",
              "      <td>-2.447001</td>\n",
              "      <td>0.765126</td>\n",
              "      <td>1.206743</td>\n",
              "      <td>-0.322237</td>\n",
              "      <td>-0.901054</td>\n",
              "      <td>-1.431367</td>\n",
              "      <td>-1.976061</td>\n",
              "      <td>0.442676</td>\n",
              "      <td>-1.184213</td>\n",
              "      <td>0.726365</td>\n",
              "      <td>-0.121266</td>\n",
              "      <td>-1.558228</td>\n",
              "      <td>0.188044</td>\n",
              "      <td>0.923733</td>\n",
              "      <td>-0.678583</td>\n",
              "      <td>0.237414</td>\n",
              "      <td>1.433563</td>\n",
              "      <td>1.251728</td>\n",
              "      <td>0.684641</td>\n",
              "      <td>0.120938</td>\n",
              "      <td>1.015380</td>\n",
              "      <td>-0.145098</td>\n",
              "      <td>-0.724019</td>\n",
              "      <td>0.097759</td>\n",
              "      <td>0.599410</td>\n",
              "      <td>-1.055248</td>\n",
              "      <td>0.792567</td>\n",
              "      <td>0.069373</td>\n",
              "      <td>-0.476264</td>\n",
              "      <td>-0.950429</td>\n",
              "      <td>-1.328681</td>\n",
              "      <td>1.108469</td>\n",
              "      <td>1.421100</td>\n",
              "      <td>1.782094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4655</th>\n",
              "      <td>-0.137148</td>\n",
              "      <td>0.426093</td>\n",
              "      <td>1.210821</td>\n",
              "      <td>0.191794</td>\n",
              "      <td>-0.006494</td>\n",
              "      <td>0.254896</td>\n",
              "      <td>0.369991</td>\n",
              "      <td>0.048274</td>\n",
              "      <td>-0.681508</td>\n",
              "      <td>-1.065203</td>\n",
              "      <td>0.500732</td>\n",
              "      <td>0.074203</td>\n",
              "      <td>0.055475</td>\n",
              "      <td>-0.974615</td>\n",
              "      <td>-0.261767</td>\n",
              "      <td>-0.665751</td>\n",
              "      <td>-0.327619</td>\n",
              "      <td>-0.258923</td>\n",
              "      <td>-1.510986</td>\n",
              "      <td>0.025884</td>\n",
              "      <td>-0.756113</td>\n",
              "      <td>0.452080</td>\n",
              "      <td>0.159331</td>\n",
              "      <td>0.553533</td>\n",
              "      <td>-0.113637</td>\n",
              "      <td>0.126934</td>\n",
              "      <td>-1.161581</td>\n",
              "      <td>-1.076479</td>\n",
              "      <td>-0.326778</td>\n",
              "      <td>1.552225</td>\n",
              "      <td>1.206025</td>\n",
              "      <td>-0.714731</td>\n",
              "      <td>0.380288</td>\n",
              "      <td>-1.210283</td>\n",
              "      <td>0.821508</td>\n",
              "      <td>-0.590951</td>\n",
              "      <td>0.193396</td>\n",
              "      <td>-0.911902</td>\n",
              "      <td>-1.367290</td>\n",
              "      <td>-0.735684</td>\n",
              "      <td>...</td>\n",
              "      <td>-2.084174</td>\n",
              "      <td>0.736843</td>\n",
              "      <td>0.509496</td>\n",
              "      <td>0.151054</td>\n",
              "      <td>1.780228</td>\n",
              "      <td>1.457690</td>\n",
              "      <td>-2.091955</td>\n",
              "      <td>0.912021</td>\n",
              "      <td>1.239685</td>\n",
              "      <td>-0.430573</td>\n",
              "      <td>-0.403024</td>\n",
              "      <td>-1.424112</td>\n",
              "      <td>-1.589285</td>\n",
              "      <td>0.558668</td>\n",
              "      <td>-1.242704</td>\n",
              "      <td>1.007287</td>\n",
              "      <td>-0.478398</td>\n",
              "      <td>-1.138150</td>\n",
              "      <td>0.485756</td>\n",
              "      <td>0.878366</td>\n",
              "      <td>-0.494733</td>\n",
              "      <td>0.391658</td>\n",
              "      <td>1.099745</td>\n",
              "      <td>1.250003</td>\n",
              "      <td>0.663833</td>\n",
              "      <td>0.087780</td>\n",
              "      <td>1.066691</td>\n",
              "      <td>-0.208362</td>\n",
              "      <td>-0.391526</td>\n",
              "      <td>-0.002979</td>\n",
              "      <td>0.859754</td>\n",
              "      <td>-1.004425</td>\n",
              "      <td>0.713781</td>\n",
              "      <td>-0.027707</td>\n",
              "      <td>0.106346</td>\n",
              "      <td>-1.166628</td>\n",
              "      <td>-1.147103</td>\n",
              "      <td>1.231942</td>\n",
              "      <td>1.503500</td>\n",
              "      <td>1.946952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>773</th>\n",
              "      <td>-0.093383</td>\n",
              "      <td>0.190471</td>\n",
              "      <td>1.417895</td>\n",
              "      <td>0.710679</td>\n",
              "      <td>-0.042956</td>\n",
              "      <td>-0.122156</td>\n",
              "      <td>0.234174</td>\n",
              "      <td>-0.041244</td>\n",
              "      <td>-0.869461</td>\n",
              "      <td>-0.619697</td>\n",
              "      <td>0.672629</td>\n",
              "      <td>-0.185873</td>\n",
              "      <td>0.140809</td>\n",
              "      <td>-1.146547</td>\n",
              "      <td>-0.085355</td>\n",
              "      <td>-0.795072</td>\n",
              "      <td>-0.532297</td>\n",
              "      <td>0.159008</td>\n",
              "      <td>-1.416956</td>\n",
              "      <td>-0.103737</td>\n",
              "      <td>-0.654620</td>\n",
              "      <td>0.189786</td>\n",
              "      <td>0.002557</td>\n",
              "      <td>0.673224</td>\n",
              "      <td>0.465495</td>\n",
              "      <td>-0.198409</td>\n",
              "      <td>-1.391201</td>\n",
              "      <td>-0.564799</td>\n",
              "      <td>-0.337994</td>\n",
              "      <td>1.113219</td>\n",
              "      <td>1.220527</td>\n",
              "      <td>-0.659541</td>\n",
              "      <td>0.142070</td>\n",
              "      <td>-1.311089</td>\n",
              "      <td>0.980968</td>\n",
              "      <td>-0.512774</td>\n",
              "      <td>0.209550</td>\n",
              "      <td>-0.573979</td>\n",
              "      <td>-1.400652</td>\n",
              "      <td>-0.695085</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.898884</td>\n",
              "      <td>0.972988</td>\n",
              "      <td>0.173581</td>\n",
              "      <td>0.036446</td>\n",
              "      <td>1.816677</td>\n",
              "      <td>1.972428</td>\n",
              "      <td>-2.657680</td>\n",
              "      <td>0.800962</td>\n",
              "      <td>1.022154</td>\n",
              "      <td>-0.543088</td>\n",
              "      <td>-0.772407</td>\n",
              "      <td>-1.075194</td>\n",
              "      <td>-1.687875</td>\n",
              "      <td>0.006302</td>\n",
              "      <td>-1.140155</td>\n",
              "      <td>0.620813</td>\n",
              "      <td>-0.395503</td>\n",
              "      <td>-1.302124</td>\n",
              "      <td>0.588786</td>\n",
              "      <td>1.133353</td>\n",
              "      <td>-0.381840</td>\n",
              "      <td>0.426047</td>\n",
              "      <td>1.051782</td>\n",
              "      <td>1.045269</td>\n",
              "      <td>0.274905</td>\n",
              "      <td>-0.151093</td>\n",
              "      <td>0.972556</td>\n",
              "      <td>0.501473</td>\n",
              "      <td>-0.598459</td>\n",
              "      <td>-0.228027</td>\n",
              "      <td>1.087544</td>\n",
              "      <td>-1.372078</td>\n",
              "      <td>0.845652</td>\n",
              "      <td>-0.075110</td>\n",
              "      <td>-0.268190</td>\n",
              "      <td>-1.039762</td>\n",
              "      <td>-0.904602</td>\n",
              "      <td>1.495311</td>\n",
              "      <td>1.673340</td>\n",
              "      <td>1.874427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1873</th>\n",
              "      <td>-0.230499</td>\n",
              "      <td>0.052956</td>\n",
              "      <td>1.370375</td>\n",
              "      <td>0.437510</td>\n",
              "      <td>-0.138539</td>\n",
              "      <td>0.133056</td>\n",
              "      <td>-0.001157</td>\n",
              "      <td>-0.194666</td>\n",
              "      <td>-0.386596</td>\n",
              "      <td>-1.186440</td>\n",
              "      <td>0.694052</td>\n",
              "      <td>0.147056</td>\n",
              "      <td>0.189822</td>\n",
              "      <td>-0.910891</td>\n",
              "      <td>-0.216458</td>\n",
              "      <td>-0.835420</td>\n",
              "      <td>-0.193399</td>\n",
              "      <td>0.020093</td>\n",
              "      <td>-1.178547</td>\n",
              "      <td>0.509490</td>\n",
              "      <td>-0.762485</td>\n",
              "      <td>0.326329</td>\n",
              "      <td>0.087707</td>\n",
              "      <td>0.724974</td>\n",
              "      <td>0.096016</td>\n",
              "      <td>-0.050847</td>\n",
              "      <td>-1.269747</td>\n",
              "      <td>-1.145822</td>\n",
              "      <td>-0.290433</td>\n",
              "      <td>1.562618</td>\n",
              "      <td>0.950127</td>\n",
              "      <td>-0.754528</td>\n",
              "      <td>0.325294</td>\n",
              "      <td>-1.142643</td>\n",
              "      <td>1.065470</td>\n",
              "      <td>-0.694742</td>\n",
              "      <td>-0.015249</td>\n",
              "      <td>-0.797069</td>\n",
              "      <td>-1.557110</td>\n",
              "      <td>-0.697580</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.780188</td>\n",
              "      <td>0.651910</td>\n",
              "      <td>0.560585</td>\n",
              "      <td>0.281210</td>\n",
              "      <td>1.931802</td>\n",
              "      <td>1.408238</td>\n",
              "      <td>-1.958823</td>\n",
              "      <td>0.954094</td>\n",
              "      <td>1.385271</td>\n",
              "      <td>-0.535826</td>\n",
              "      <td>-0.895289</td>\n",
              "      <td>-1.331148</td>\n",
              "      <td>-1.782487</td>\n",
              "      <td>0.319400</td>\n",
              "      <td>-1.140346</td>\n",
              "      <td>0.878706</td>\n",
              "      <td>-0.333297</td>\n",
              "      <td>-1.220645</td>\n",
              "      <td>0.131700</td>\n",
              "      <td>0.992615</td>\n",
              "      <td>-0.571998</td>\n",
              "      <td>0.523701</td>\n",
              "      <td>1.269993</td>\n",
              "      <td>1.374680</td>\n",
              "      <td>0.552120</td>\n",
              "      <td>-0.122707</td>\n",
              "      <td>1.069480</td>\n",
              "      <td>0.130410</td>\n",
              "      <td>-0.721968</td>\n",
              "      <td>-0.348346</td>\n",
              "      <td>0.638078</td>\n",
              "      <td>-1.146326</td>\n",
              "      <td>0.888094</td>\n",
              "      <td>0.039827</td>\n",
              "      <td>-0.304646</td>\n",
              "      <td>-0.830831</td>\n",
              "      <td>-1.303204</td>\n",
              "      <td>1.332081</td>\n",
              "      <td>1.469017</td>\n",
              "      <td>1.729200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows Ã— 768 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       765       766       767\n",
              "5729 -0.134583  0.062177  1.458376  ...  1.415123  1.648605  1.899328\n",
              "3847 -0.185526  0.409991  1.526158  ...  1.282915  1.504017  1.951632\n",
              "107  -0.220425  0.316685  1.346640  ...  1.195942  1.423452  2.081895\n",
              "5367 -0.124028  0.129488  1.454345  ...  1.232159  1.433496  1.921171\n",
              "124  -0.113379  0.173708  1.133063  ...  1.292799  1.295327  2.049123\n",
              "1566  0.160529  0.144989  1.300389  ...  1.400331  1.764525  2.005513\n",
              "2588 -0.141780  0.120551  1.292551  ...  1.108469  1.421100  1.782094\n",
              "4655 -0.137148  0.426093  1.210821  ...  1.231942  1.503500  1.946952\n",
              "773  -0.093383  0.190471  1.417895  ...  1.495311  1.673340  1.874427\n",
              "1873 -0.230499  0.052956  1.370375  ...  1.332081  1.469017  1.729200\n",
              "\n",
              "[10 rows x 768 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K68gPiRzVs5S",
        "outputId": "eb62c6c1-cb0c-4dc2-b8fd-b2c7ed53fcde"
      },
      "source": [
        "# Print y shape, head, unique values and number of instances in each class\n",
        "print(y.shape)\n",
        "print(y.unique())\n",
        "print(y.value_counts())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6354,)\n",
            "[1. 2. 0.]\n",
            "2.0    2918\n",
            "1.0    1794\n",
            "0.0    1642\n",
            "Name: Recipient Gender, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2PF_KelLVvQr"
      },
      "source": [
        "# Feature extraction\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Train/Test splitting\n",
        "from sklearn import model_selection\n",
        "\n",
        "# Hyper-parameter tuning\n",
        "from sklearn.model_selection import RandomizedSearchCV,  GridSearchCV, cross_val_score\n",
        "\n",
        "# Classifiers\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "# Classifier evaluation metrics\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, make_scorer, confusion_matrix, classification_report\n",
        "\n",
        "# Print confusion matrix\n",
        "import seaborn as sns"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsIFk6KnVyTJ",
        "outputId": "27ae64ac-beb6-46ac-b3e6-317e838f27bb"
      },
      "source": [
        "# split into training and test set\n",
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5083, 768)\n",
            "(5083,)\n",
            "(1271, 768)\n",
            "(1271,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "or69yK7wWgZx"
      },
      "source": [
        "svm_clf = SVC(C=10, gamma=0.1, probability=True)\n",
        "rf_clf = RandomForestClassifier(max_depth=50, min_samples_leaf=3, min_samples_split=3)\n",
        "mlp_clf = MLPClassifier(alpha=0.05, hidden_layer_sizes=(50, 100, 50))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90ttyo7yWm8Y",
        "outputId": "f64a051a-02f5-4c1c-8735-1f1715a5bb93"
      },
      "source": [
        "svm_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "mlp_clf.fit(X_train, y_train)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.05, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(50, 100, 50), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs36_e2OWpzu"
      },
      "source": [
        "\n",
        "def print_results(clf, y_pred):\n",
        "    # Print accuracy score \n",
        "    print(\"Accuracy Score -> \",accuracy_score(y_pred, y_test)*100)\n",
        "    \n",
        "    # Print confusion matrix (heat map)\n",
        "    sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='g')\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    \n",
        "    # Print avarage 10-fold cross validation accuracy and f1 scores \n",
        "    #svm_cv_accuracy_score = cross_val_score(clf, X_train, y_train, cv=10,scoring='accuracy')\n",
        "    #svm_cv_f1_score = cross_val_score(clf, X_train, y_train, cv=10,scoring='f1_macro')\n",
        "    #print(\"Mean cv accuracy: \", svm_cv_accuracy_score.mean())\n",
        "    #print(\"Mean cv f1_macro: \", svm_cv_f1_score.mean())"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "YwrRPyUeWrmr",
        "outputId": "e1d31de3-433e-4a5e-8f6e-fc4682f9c2e6"
      },
      "source": [
        "# predict recipient gender and print prediction results\n",
        "y_pred = svm_clf.predict(X_test)\n",
        "print_results(svm_clf, y_pred)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  48.229740361919745\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.30      0.16      0.21       330\n",
            "         1.0       0.42      0.34      0.38       382\n",
            "         2.0       0.55      0.77      0.64       559\n",
            "\n",
            "    accuracy                           0.48      1271\n",
            "   macro avg       0.42      0.42      0.41      1271\n",
            "weighted avg       0.44      0.48      0.45      1271\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "yV2NNFA0Wtif",
        "outputId": "977f7804-4ece-4f7e-98e1-5c77a2be1fee"
      },
      "source": [
        "# predict recipient gender and print prediction results\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "print_results(rf_clf, y_pred)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  49.09520062942565\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.09      0.14       330\n",
            "         1.0       0.45      0.26      0.33       382\n",
            "         2.0       0.52      0.89      0.66       559\n",
            "\n",
            "    accuracy                           0.49      1271\n",
            "   macro avg       0.42      0.41      0.37      1271\n",
            "weighted avg       0.44      0.49      0.42      1271\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "YJc2mgUVWwS1",
        "outputId": "bf61d689-5fd4-483b-d402-491b05404c55"
      },
      "source": [
        "# predict recipient gender and print prediction results\n",
        "y_pred = mlp_clf.predict(X_test)\n",
        "print_results(mlp_clf, y_pred)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  44.76789929189614\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.33      0.23      0.27       330\n",
            "         1.0       0.34      0.39      0.37       382\n",
            "         2.0       0.56      0.62      0.59       559\n",
            "\n",
            "    accuracy                           0.45      1271\n",
            "   macro avg       0.41      0.41      0.41      1271\n",
            "weighted avg       0.44      0.45      0.44      1271\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "id": "VTGvXpeAWybS",
        "outputId": "b805fa5b-4219-47d0-8409-25295d0ba495"
      },
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "clf = DummyClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# predict recipient gender and print prediction results\n",
        "y_pred = clf.predict(X_test)\n",
        "print_results(clf, y_pred)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  34.77576711250984\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/dummy.py:132: FutureWarning: The default value of strategy will change from stratified to prior in 0.24.\n",
            "  \"stratified to prior in 0.24.\", FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.29      0.29      0.29       330\n",
            "         1.0       0.28      0.24      0.26       382\n",
            "         2.0       0.42      0.45      0.43       559\n",
            "\n",
            "    accuracy                           0.35      1271\n",
            "   macro avg       0.33      0.33      0.33      1271\n",
            "weighted avg       0.34      0.35      0.34      1271\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}